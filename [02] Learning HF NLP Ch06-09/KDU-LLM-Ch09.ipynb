{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["JxCTrQ8xZRhN","bYdxDkejZSRE","9mcBjSR5ZTJT","kjlKJHjRZUE0","6mTfqPu2ZU0e","8avxDzlPZVZi"],"authorship_tag":"ABX9TyOfyTPZizxNgTfM/QJZIPxg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JxCTrQ8xZRhN"},"source":["# Building your first demo"]},{"cell_type":"markdown","metadata":{"id":"snY-W3N6ZRhP"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Shnb8B6rZRhQ"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTVgKgieZRhR"},"outputs":[],"source":["import gradio as gr\n","\n","\n","def greet(name):\n","    return \"Hello \" + name\n","\n","\n","demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNqLKXuUZRhR"},"outputs":[],"source":["import gradio as gr\n","\n","\n","def greet(name):\n","    return \"Hello \" + name\n","\n","\n","# We instantiate the Textbox class\n","textbox = gr.Textbox(label=\"Type your name here:\", placeholder=\"John Doe\", lines=2)\n","\n","gr.Interface(fn=greet, inputs=textbox, outputs=\"text\").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-vF0Cb1ZRhR"},"outputs":[],"source":["from transformers import pipeline\n","\n","model = pipeline(\"text-generation\")\n","\n","\n","def predict(prompt):\n","    completion = model(prompt)[0][\"generated_text\"]\n","    return completion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbm9LC5rZRhS"},"outputs":[],"source":["import gradio as gr\n","\n","gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\").launch()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"HNS1MgYUZvPa"}},{"cell_type":"markdown","metadata":{"id":"bYdxDkejZSRE"},"source":["# Understanding the Interface class"]},{"cell_type":"markdown","metadata":{"id":"CFypezWfZSRH"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QUmb8AxZSRH"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITca34BaZSRI"},"outputs":[],"source":["import numpy as np\n","import gradio as gr\n","\n","\n","def reverse_audio(audio):\n","    sr, data = audio\n","    reversed_audio = (sr, np.flipud(data))\n","    return reversed_audio\n","\n","\n","mic = gr.Audio(source=\"microphone\", type=\"numpy\", label=\"Speak here...\")\n","gr.Interface(reverse_audio, mic, \"audio\").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lDCcbcZZSRJ"},"outputs":[],"source":["import numpy as np\n","import gradio as gr\n","\n","notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n","\n","\n","def generate_tone(note, octave, duration):\n","    sr = 48000\n","    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n","    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n","    duration = int(duration)\n","    audio = np.linspace(0, duration, duration * sr)\n","    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n","    return (sr, audio)\n","\n","\n","gr.Interface(\n","    generate_tone,\n","    [\n","        gr.Dropdown(notes, type=\"index\"),\n","        gr.Slider(minimum=4, maximum=6, step=1),\n","        gr.Textbox(type=\"number\", value=1, label=\"Duration in seconds\"),\n","    ],\n","    \"audio\",\n",").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IeX3CV2ZZSRJ"},"outputs":[],"source":["from transformers import pipeline\n","import gradio as gr\n","\n","model = pipeline(\"automatic-speech-recognition\")\n","\n","\n","def transcribe_audio(mic=None, file=None):\n","    if mic is not None:\n","        audio = mic\n","    elif file is not None:\n","        audio = file\n","    else:\n","        return \"You must either provide a mic recording or a file\"\n","    transcription = model(audio)[\"text\"]\n","    return transcription\n","\n","\n","gr.Interface(\n","    fn=transcribe_audio,\n","    inputs=[\n","        gr.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n","        gr.Audio(source=\"upload\", type=\"filepath\", optional=True),\n","    ],\n","    outputs=\"text\",\n",").launch()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"iZriOEb5Zwyq"}},{"cell_type":"markdown","metadata":{"id":"9mcBjSR5ZTJT"},"source":["# Sharing demos with others"]},{"cell_type":"markdown","metadata":{"id":"hd0HmLYUZTJV"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uvZ9T-6ZTJW"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjWmpD6VZTJX"},"outputs":[],"source":["title = \"Ask Rick a Question\"\n","description = \"\"\"\n","The bot was trained to answer questions based on Rick and Morty dialogues. Ask Rick anything!\n","<img src=\"https://huggingface.co/spaces/course-demos/Rick_and_Morty_QA/resolve/main/rick.png\" width=200px>\n","\"\"\"\n","\n","article = \"Check out [the original Rick and Morty Bot](https://huggingface.co/spaces/kingabzpro/Rick_and_Morty_Bot) that this demo is based off of.\"\n","\n","gr.Interface(\n","    fn=predict,\n","    inputs=\"textbox\",\n","    outputs=\"text\",\n","    title=title,\n","    description=description,\n","    article=article,\n","    examples=[[\"What are you doing?\"], [\"Where should we time travel to?\"]],\n",").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84je3zcVZTJX"},"outputs":[],"source":["gr.Interface(classify_image, \"image\", \"label\").launch(share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQ_qxaCXZTJX"},"outputs":[],"source":["from pathlib import Path\n","import torch\n","import gradio as gr\n","from torch import nn\n","\n","LABELS = Path(\"class_names.txt\").read_text().splitlines()\n","\n","model = nn.Sequential(\n","    nn.Conv2d(1, 32, 3, padding=\"same\"),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(32, 64, 3, padding=\"same\"),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(64, 128, 3, padding=\"same\"),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2),\n","    nn.Flatten(),\n","    nn.Linear(1152, 256),\n","    nn.ReLU(),\n","    nn.Linear(256, len(LABELS)),\n",")\n","state_dict = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n","model.load_state_dict(state_dict, strict=False)\n","model.eval()\n","\n","\n","def predict(im):\n","    x = torch.tensor(im, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0\n","    with torch.no_grad():\n","        out = model(x)\n","    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n","    values, indices = torch.topk(probabilities, 5)\n","    return {LABELS[i]: v.item() for i, v in zip(indices, values)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwslR0mHZTJY"},"outputs":[],"source":["interface = gr.Interface(\n","    predict,\n","    inputs=\"sketchpad\",\n","    outputs=\"label\",\n","    theme=\"huggingface\",\n","    title=\"Sketch Recognition\",\n","    description=\"Who wants to play Pictionary? Draw a common object like a shovel or a laptop, and the algorithm will guess in real time!\",\n","    article=\"<p style='text-align: center'>Sketch Recognition | Demo Model</p>\",\n","    live=True,\n",")\n","interface.launch(share=True)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"IZ0moOU-ZymT"}},{"cell_type":"markdown","metadata":{"id":"kjlKJHjRZUE0"},"source":["# Integrations with the Hugging Face Hub"]},{"cell_type":"markdown","metadata":{"id":"naTtToZBZUE3"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phtICfRmZUE4"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPb8qe6EZUE5"},"outputs":[],"source":["import gradio as gr\n","\n","title = \"GPT-J-6B\"\n","description = \"Gradio Demo for GPT-J 6B, a transformer model trained using Ben Wang's Mesh Transformer JAX. 'GPT-J' refers to the class of model, while '6B' represents the number of trainable parameters. To use it, simply add your text, or click one of the examples to load them. Read more at the links below.\"\n","article = \"<p style='text-align: center'><a href='https://github.com/kingoflolz/mesh-transformer-jax' target='_blank'>GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model</a></p>\"\n","examples = [\n","    [\"The tower is 324 metres (1,063 ft) tall,\"],\n","    [\"The Moon's orbit around Earth has\"],\n","    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"],\n","]\n","gr.Interface.load(\n","    \"huggingface/EleutherAI/gpt-j-6B\",\n","    inputs=gr.Textbox(lines=5, label=\"Input Text\"),\n","    title=title,\n","    description=description,\n","    article=article,\n","    examples=examples,\n","    enable_queue=True,\n",").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMiOMRXpZUE5"},"outputs":[],"source":["gr.Interface.load(\"spaces/abidlabs/remove-bg\").launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VXvkFY_ZUE6"},"outputs":[],"source":["gr.Interface.load(\n","    \"spaces/abidlabs/remove-bg\", inputs=\"webcam\", title=\"Remove your webcam background!\"\n",").launch()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"-c_8BhfMZz7a"}},{"cell_type":"markdown","metadata":{"id":"6mTfqPu2ZU0e"},"source":["# Advanced Interface features"]},{"cell_type":"markdown","metadata":{"id":"U-X0-Q19ZU0h"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtlEcX6mZU0h"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqTOQOsjZU0i"},"outputs":[],"source":["import random\n","\n","import gradio as gr\n","\n","\n","def chat(message, history):\n","    history = history or []\n","    if message.startswith(\"How many\"):\n","        response = random.randint(1, 10)\n","    elif message.startswith(\"How\"):\n","        response = random.choice([\"Great\", \"Good\", \"Okay\", \"Bad\"])\n","    elif message.startswith(\"Where\"):\n","        response = random.choice([\"Here\", \"There\", \"Somewhere\"])\n","    else:\n","        response = \"I don't know\"\n","    history.append((message, response))\n","    return history, history\n","\n","\n","iface = gr.Interface(\n","    chat,\n","    [\"text\", \"state\"],\n","    [\"chatbot\", \"state\"],\n","    allow_screenshot=False,\n","    allow_flagging=\"never\",\n",")\n","iface.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lavGr8WZZU0j"},"outputs":[],"source":["import requests\n","import tensorflow as tf\n","\n","import gradio as gr\n","\n","inception_net = tf.keras.applications.MobileNetV2()  # load the model\n","\n","# Download human-readable labels for ImageNet.\n","response = requests.get(\"https://git.io/JJkYN\")\n","labels = response.text.split(\"\\n\")\n","\n","\n","def classify_image(inp):\n","    inp = inp.reshape((-1, 224, 224, 3))\n","    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n","    prediction = inception_net.predict(inp).flatten()\n","    return {labels[i]: float(prediction[i]) for i in range(1000)}\n","\n","\n","image = gr.Image(shape=(224, 224))\n","label = gr.Label(num_top_classes=3)\n","\n","title = \"Gradio Image Classifiction + Interpretation Example\"\n","gr.Interface(\n","    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\", title=title\n",").launch()"]},{"cell_type":"markdown","metadata":{"id":"8avxDzlPZVZi"},"source":["# Introduction to Blocks"]},{"cell_type":"markdown","metadata":{"id":"vwDrWsVkZVZl"},"source":["Install the Transformers, Datasets, and Evaluate libraries to run this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-dQctHaZVZl"},"outputs":[],"source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhrpR0x9ZVZm"},"outputs":[],"source":["import gradio as gr\n","\n","\n","def flip_text(x):\n","    return x[::-1]\n","\n","\n","demo = gr.Blocks()\n","\n","with demo:\n","    gr.Markdown(\n","        \"\"\"\n","    # Flip Text!\n","    Start typing below to see the output.\n","    \"\"\"\n","    )\n","    input = gr.Textbox(placeholder=\"Flip this text\")\n","    output = gr.Textbox()\n","\n","    input.change(fn=flip_text, inputs=input, outputs=output)\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEjXPTDQZVZn"},"outputs":[],"source":["import numpy as np\n","import gradio as gr\n","\n","demo = gr.Blocks()\n","\n","\n","def flip_text(x):\n","    return x[::-1]\n","\n","\n","def flip_image(x):\n","    return np.fliplr(x)\n","\n","\n","with demo:\n","    gr.Markdown(\"Flip text or image files using this demo.\")\n","    with gr.Tabs():\n","        with gr.TabItem(\"Flip Text\"):\n","            with gr.Row():\n","                text_input = gr.Textbox()\n","                text_output = gr.Textbox()\n","            text_button = gr.Button(\"Flip\")\n","        with gr.TabItem(\"Flip Image\"):\n","            with gr.Row():\n","                image_input = gr.Image()\n","                image_output = gr.Image()\n","            image_button = gr.Button(\"Flip\")\n","\n","    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n","    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eu-2YEI7ZVZn"},"outputs":[],"source":["import gradio as gr\n","\n","api = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\n","\n","\n","def complete_with_gpt(text):\n","    # Use the last 50 characters of the text as context\n","    return text[:-50] + api(text[-50:])\n","\n","\n","with gr.Blocks() as demo:\n","    textbox = gr.Textbox(placeholder=\"Type here and press enter...\", lines=4)\n","    btn = gr.Button(\"Generate\")\n","\n","    btn.click(complete_with_gpt, textbox, textbox)\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iaid1gwgZVZn"},"outputs":[],"source":["from transformers import pipeline\n","\n","import gradio as gr\n","\n","asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n","classifier = pipeline(\"text-classification\")\n","\n","\n","def speech_to_text(speech):\n","    text = asr(speech)[\"text\"]\n","    return text\n","\n","\n","def text_to_sentiment(text):\n","    return classifier(text)[0][\"label\"]\n","\n","\n","demo = gr.Blocks()\n","\n","with demo:\n","    audio_file = gr.Audio(type=\"filepath\")\n","    text = gr.Textbox()\n","    label = gr.Label()\n","\n","    b1 = gr.Button(\"Recognize Speech\")\n","    b2 = gr.Button(\"Classify Sentiment\")\n","\n","    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n","    b2.click(text_to_sentiment, inputs=text, outputs=label)\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9QLpLpaZVZo"},"outputs":[],"source":["import gradio as gr\n","\n","\n","def change_textbox(choice):\n","    if choice == \"short\":\n","        return gr.Textbox.update(lines=2, visible=True)\n","    elif choice == \"long\":\n","        return gr.Textbox.update(lines=8, visible=True)\n","    else:\n","        return gr.Textbox.update(visible=False)\n","\n","\n","with gr.Blocks() as block:\n","    radio = gr.Radio(\n","        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n","    )\n","    text = gr.Textbox(lines=2, interactive=True)\n","\n","    radio.change(fn=change_textbox, inputs=radio, outputs=text)\n","    block.launch()"]}]}